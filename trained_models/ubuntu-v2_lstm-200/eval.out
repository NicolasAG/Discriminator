removed environment variable LD_LIBRARY_PATH from submit environment - it is considered a security issue
VIRTUALENV = /nlu/users/nicolas_gontier/py
THEANO_FLAGS = base_compiledir=/work/.theano-nicolas_gontier,floatX=float32,device=gpu
gpuarray = /nlu/users/nicolas_gontier/py/lib/python2.7/site-packages/libgpuarray
CUDA = /usr/local/cuda-8.0/bin
PATH = /usr/local/cuda-8.0/bin:/nlu/users/nicolas_gontier/py/bin:/work/5398661.1.gpu.q:/opt/rh/devtoolset-2/root/usr/bin:/opt/uge850/bin:/opt/uge850/bin/lx-amd64:/usr/lib64/qt-3.3/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/ibutils/bin:/home/nicolas_gontier/bin
LD_LIBRARY_PATH = :/usr/local/cuda-8.0/lib64
LIBRARY_PATH = /nlu/users/nicolas_gontier/py/lib
CPATH = /nlu/users/nicolas_gontier/py/include
HOME = /nlu/users/nicolas_gontier/home

Using gpu device 0: Tesla K10.G1.8GB (CNMeM is disabled, cuDNN 5105)
/nlu/users/nicolas_gontier/py/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.
  warnings.warn(warn)
2017-06-23 15:36:31,227: __main__: INFO: args: Namespace(W_fname='W_glove.pkl', act_penalty=500, batch_size=256, data_path='./ubuntu_dataset/v2', dataset_fname='DE_dataset.pkl', dropout_in=0.0, dropout_out=0.0, emb_penalty=0.001, encoder='rnn', fine_tune_M=False, fine_tune_W=False, hidden_size=200, is_bidirectional=False, k=4, load_path='./trained_models/ubuntu-v2_lstm-200', load_prefix='lstm-200_adam_ubuntu-v2', lr=0.001, lr_decay=0.95, max_seqlen=160, n_epochs=100, n_recurrent_layers=1, optimizer='adam', patience=10, penalize_activations=False, penalize_emb_drift=False, penalize_emb_norm=False, plot_human_scores=False, plot_learning_curves=True, plot_response_length=False, resume=False, retrieve=False, save_path='.', save_prefix='lstm-200_adam_ubuntu-v2', seed=4213, sort_by_len=False, test=True, train_examples=None, use_ntn=False)
2017-06-23 15:36:31,231: __main__: INFO: saved.
2017-06-23 15:36:31,231: __main__: INFO:
2017-06-23 15:36:31,231: __main__: INFO: Loading data...
2017-06-23 15:37:26,055: __main__: INFO: W.shape: (858977, 300)
2017-06-23 15:37:26,055: __main__: INFO: Number of training examples: 1000192
2017-06-23 15:37:26,055: __main__: INFO: Number of validation examples: 195600
2017-06-23 15:37:26,055: __main__: INFO: Number of test examples: 189200
2017-06-23 15:37:26,055: __main__: INFO: data loaded!
2017-06-23 15:37:26,055: __main__: INFO:
2017-06-23 15:37:26,056: __main__: INFO: Loading model...
2017-06-23 15:38:32,607: __main__: INFO: Model loaded.
2017-06-23 15:38:32,607: __main__: INFO:
2017-06-23 15:38:32,609: __main__: INFO: plot learning curves...
2017-06-23 15:38:32,946: model: INFO: saved plot.
2017-06-23 15:38:33,165: model: INFO: saved plot.
2017-06-23 15:38:33,166: __main__: INFO:
2017-06-23 15:38:33,166: __main__: INFO: Testing the model...
2017-06-23 15:38:33,475: model: INFO: evaluating rand
2017-06-23 15:50:27,898: model: INFO: test_perf: 80.204369274%
2017-06-23 15:50:27,898: model: INFO: evaluating true
2017-06-23 15:51:45,920: model: INFO: test_perf: 73.821353066%
2017-06-23 15:51:45,921: model: INFO:
2017-06-23 15:51:45,921: model: DEBUG: verifying data format for recalls...
2017-06-23 15:51:45,921: model: DEBUG: ok. computing 189440 probabilities now...
2017-06-23 16:04:56,188: model: INFO: Computing recalls...
2017-06-23 16:04:56,188: model: INFO: group_size: 2
2017-06-23 16:04:56,917: model: INFO: recall@1 = 0.855549682875
2017-06-23 16:04:56,917: model: INFO: group_size: 5
2017-06-23 16:04:57,695: model: INFO: recall@1 = 0.661363636364
2017-06-23 16:04:58,461: model: INFO: recall@2 = 0.848942917548
2017-06-23 16:04:58,461: model: INFO: group_size: 10
2017-06-23 16:04:59,368: model: INFO: recall@1 = 0.528276955603
2017-06-23 16:05:00,267: model: INFO: recall@2 = 0.703382663848
2017-06-23 16:05:01,170: model: INFO: recall@5 = 0.915803382664
2017-06-23 16:05:01,171: model: INFO:
2017-06-23 16:05:01,171: model: INFO: Average test_perf=77.012861170%

